<!DOCTYPE html>
<html>

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>
    body {
      font-family: "Lato", sans-serif;
    }
    
    .sidenav {
      width: 260px;
      position: fixed;
      z-index: 1;
      top: 200px;
      left: 10px;
      background: #eee;
      overflow-x: hidden;
      padding: 8px 0;
    }
    
    .sidenav a {
      padding: 6px 8px 6px 16px;
      text-decoration: none;
      font-size: 25px;
      color: #2196F3;
      display: block;
    }
    
    .sidenav a:hover {
      color: #064579;
    }
    
    .main {
      margin-left: 280px; /* Same width as the sidebar + left position in px */
      font-size: 24px; /* Increased text to enable scrolling */
      padding: 0px 10px;
    }
    
    @media screen and (max-height: 450px) {
      .sidenav {padding-top: 15px;}
      .sidenav a {font-size: 18px;}
    }
    </style>
    </head>

<body>

    <div  class="main">
<h1>    XMRec: Cross-Market Recommendation Competition @ WSDM 2022</h1>
</div>

<div class="sidenav">
    <a class="active" href="#overview" data-toggle="tab">Overview</a>
    <a href="#task" data-toggle="tab">Task</a>
    <a href="#evaluation" data-toggle="tab">Evaluation</a>
    <a href="#data" data-toggle="tab">Data</a>
    <a href="#terms" data-toggle="tab">Terms and Conditions</a>
    <a href="#organizer" data-toggle="tab">Organizers</a>
    <a href="#contact" data-toggle="tab">Contact</a>
  </div>


  <div  class="main">
    <div>
        
        <div class="tab-pane active" id="overview">
            
            <h2 id="XMRec">XMRec</h2>
            <p>
                E-commerce companies often operate across markets; for instance 
            <a  href="https://www.amazon.com">Amazon</a> 
                has expanded their operations and sales to 18 markets (i.e. countries) around the globe. 
                The cross-market recommendation concerns the problem of recommending relevant products to users in a target market (e.g., a resource-scarce market) by leveraging data from similar high-resource markets, e.g. using data from the U.S. market to improve recommendations in a target market. 
                The key challenge, however, is that data, such as user interaction data with products (clicks, purchases, reviews), convey certain biases of the individual markets. 
                Therefore, the algorithms trained on a source market are not necessarily effective in a different target market.
            </p>
            <p>
                Despite its significance, small progress has been made in cross-market recommendation, mainly due to a lack of experimental data for the researchers. In this WSDM Cup challenge, we provide user purchase and rating data on various markets, enriched with review data in different languages, with a considerable number of shared item subsets. The goal is to improve individual recommendation systems in these target markets by leveraging data from similar auxiliary markets.
                For more information please go to 
            <a href="https://xmrec.github.io">XMRec websit</a>
            </p>
                
        </div>
        <div class="tab-pane active" id="task">
            <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
            <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
            
            <style>
                mark { 
                  background-color: rgb(216, 216, 216);
                  color: black;
                }
                </style>
            
            <h2>Task</h2>
            <h3>Problem Definition</h3>
            <p>
                Given a global set of items \(\mathcal{I}\), 
                we define a market \(\mathbb{M}\) as the collection of its users \(U(\mathbb{M})\) together with their interactions (i.e. ratings and reviews) with items from \(\mathcal{I}\).
                Generally, a user can interact with different markets, but for simplicity, we assume that the set of users in each market are mutually disjoint with any other parallel market.
                In this competition, we have three source markets, \(\{S_{1}, S_{2}, S_{3}\}\), and two target markets, \(\{T_{1}, T_{2}\}\). 
                
                The goal is to have the best possible recommender system in terms of nDCG@10 on the target markets \(\{T_{1}, T_{2}\}\).
                For that, you can use the data on these markets and also get help from the data available from the source markets \(\{S_{1}, S_{2}, S_{3}\}\).
            </p>
            
            <h3>Train, Validation, and Test Split</h3>
            <p>
                The source markets are used for training, and therefore they are provided in a single <b>Train</b> split.
                For the target markets, we leave one interaction of each user out for the <b>Test</b> split, and one other interaction for the <b>Validation</b> split. All the remaining interactions are given as the <b>Train</b> split. As usual, you are given only the Train and Validation splits.
            </p>
            
            <h3 id=submissions>Submissions</h3>
            <p>
                Your submissions should be two tab separated files (<mark><code>target_1.scores.tsv</code></mark> and <mark><code>target_2.scores.tsv</code></mark>) with each line containing three columns as follows:
            
                <p><code>
                    userId	itemId	score
                </code></p>
                where the first column <code>userId</code> is the user unique id, the second column <code>itemId</code> is the item unique id, and the third column <code>score</code> is the score your model assigns to this (user, item) pair.
                For example, each of your <mark><code>.score.tsv</code></mark> files should look like this:
                <p><code>
                    VA	E2	1.0 
                    VA	FQ	0.9 
                    VA	WS	1.1
                    ...
                </code></p>
                For each user (i.e. each unique value for <code>userId</code>), the items are sorted based on their score in a descending order (equal scores are handled randomly) and the top 10 items in the ranked list are used for <a href=#evaluation>evaluation</a>.
            </p>
            
        </div>
        <div class="tab-pane active" id="evaluation">
            <style>
                mark { 
                  background-color: rgb(216, 216, 216);
                  color: black;
                }
                </style>
            
            <h2 id="Evaluation">Evaluation</h2>
            <p>
                We evaluate the submissions based on their average nDCG@10.
                As discussed in submission guidlines, the scores of items are sorted for each user and the top 10 items are considered for evaluation.
                For the total evaluation, we concatenate the users of the target markets (<mark><code>target_1.scores.tsv</code></mark> and <mark><code>target_2.scores.tsv</code></mark>) and compute the nDCG@10 on the resulting list. The teams are ranked based on this metric.
                <br>
                For information purposes we also report separate nDCG@10 and HR@10 for each target market, too.
            </p>
        </div>
        <div class="tab-pane active" id="data">
            <style>
                mark { 
                  background-color: rgb(216, 216, 216);
                  color: black;
                }
                li{
                    margin: 10px 0;
                } 
            </style>
            
            <h2>Data</h2>
            <p>The training and validation as well as the test run can be downloaded <a href="#">here</a>.
            <p>The data is structured as follows:</p>
            <ul>
                <li>There are three folders 
                    <mark><code>source_1</code></mark>,
                    <mark><code>source_2</code></mark>, and 
                    <mark><code>source_3</code></mark>;
                    containing the data of the source markets. Inside each, the following file can be found:
                    <ul>
                        <li>
                            <mark><code>train.tsv</code></mark>: A tab separated file, containing the <b>Training</b> data with the following format:
                            <p><code>
                                userId	itemId	rating
                            </p></code>
                            where the first column <code>userId</code> is the user unique id, the second column <code>itemId</code> is the item unique id, and the third column <code>rating</code> is the rating (an integer ranging from 1 to 5).
                            This means that our training data only contains the <b>positive</b> samples. All the other (user, item) pairs are unknown and can be considered <b>negative</b> during training.
                        </li>
                    </ul>
                </li>
                <li>
                    There are two folders
                    <mark><code>target_1</code></mark>, and 
                    <mark><code>target_2</code></mark>; containing the data of the target markets. Inside each, the following files can be found:
                    <ul>
                        <li>
                            <mark><code>train.tsv</code></mark>: 
                            A tab separated file, containing the <b>Training</b> data with <code>userId</code>, <code>itemId</code>, and <code>rating</code> fields the same as above.
                        </li>
                        <li>
                            <mark><code>valid_qrel.tsv</code></mark>:
                            The <b>Validation positive</b> samples, with a structure similar to the <mark><code>train.tsv</code></mark>.
                            Note that, the validation set only has one positive sample per user.
                        </li>
                        <li>
                            <mark><code>valid_qrun.tsv</code></mark>:
                            The <b>Validation</b> samples. For consistency of results between different teams, we provide you 99 negative samples for each unique <code>userId</code> as follows:
                            <p><code>
                                userId	itemId1,itemId2,...,itemId100
                            </code></p>
                            where the two columns are separated by a tab and the list of items are separated by commas. There are 99 negative samples and 1 positive sample (identified in the <mark><code>valid_qrel.tsv</code></mark> file) in the list. Your model should rerank these 100 items per user.
                        </li>
                        <li>
                            <mark><code>test_qrun.tsv</code></mark>:
                            The <b>Test candidate</b> samples. As is common in recommendation systems, we provide you 100 candidate items for each unique <code>userId</code> as follows:
                            <p><code>
                                userId	itemId1,itemId2,...,itemId100
                            </code></p>
                            where the two columns are separated by a tab and the list of negative items are separated by commas.
                            These 100 items should be reranked by your models and the top 10 items for each user should be reported with their scores.
                            Only one item from this list of 100 items is a positive sample and the rest 99 items are negative samples.
                        </li>
                    </ul>
                </li>
            </ul>
            
        </div>
        <div class="tab-pane active" id="terms">
            <h2>Terms and Conditions</h2>
            <p>The XMRec dataset is free to download for research purposes.</p>
        </div>

        <div class="tab-pane active" id="organizer">
            <h2>Organizers</h2>
            <ul>
                <li>
                    <a href=http://aliannejadi.com>Mohammad Aliannejadi</a>, University of Amsterdam, The Netherlands
                </li>
                <li>
                    <a href="https://people.cs.umass.edu/~bonab/">Hamed Bonab</a>, University of Massachusetts Amherst, USA
                </li>
                <li>
                    Ali Vardasbi, University of Amsterdam, The Netherlands
                </li>
                <li>
                    <a href="https://staff.fnwi.uva.nl/e.kanoulas/">Evangelos Kanoulas</a>, University of Amsterdam, The Netherlands
                </li>
                <li>
                    <a href="http://ciir.cs.umass.edu/~allan/">James Allan</a>, University of Massachusetts Amherst, USA
                </li>
            </ul>
        </div>
        
        <div class="tab-pane active" id="contact">
            <h2>Contact</h2>
            <p>For queries, please contact us via <a href=mailto:m.aliannejadi@uva.nl>m.aliannejadi@uva.nl</a>.</p>
        </div>
    </div>
</div>

</body>
</html>
